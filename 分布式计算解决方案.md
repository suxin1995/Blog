传统数据处理架构是典型以数据库为中心，数据常以批量方式进行处理。

流处理框架结合消息传输层（kafka）及流处理层技术(flink)。

[参考链接](!https://zhuanlan.zhihu.com/p/104585830)

相较于lambda架构（需要开发同样逻辑代码，维护成本高）、kappa架构、flink



https://zhuanlan.zhihu.com/p/94302767

数据都是以流的形式产生。可分为有界与无界。批量处理实际是一个有界的数据流，是流处理的特例。

分布式计算 较成熟的解决方案MPI 与MapReduce（相较于前者，对大部分原始问题进行封装）

基于MapReduce 编程模型，不同团队实现不同大数据框架 如hadoop、spark、flink

hadoop在数据分析处理领域发展成为一个大生态圈，涵盖大量大数据相关服务。

spark擅长批处理，flink主要面向流处理，都是针对大数据计算。

flink被设计为在所有常见集群环境运行，以内存速度和任何规模执行计算。（可集成到hadoop生态上）

- flink支持"exactly once"，即事件投递保证只有一次，数据的准确性能得到提升
- 以事件为单位，达到真正意义上的实时计算，且所需计算资源相对更少
- 吞吐量更高，延迟更低，准确性能得到保障



Flink环境搭建



Python 作业

- 环境搭建 
  - pip install apache-Flink



可独立部署，也可嵌入hadoop中作为套件服务。

```
sudo xattr -d com.apple.quarantine /Applications/Navicat Premium.app
```