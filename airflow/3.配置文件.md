## airflow1.10配置文件

```bash
# dag存放目录
dags_folder = /hadoop/airflow/dags

# 日志存放目录
base_log_folder = /hadoop/airflow/logs

# 设置web端Configuration不显示配置信息
expose_config = False

#控制 Airflow worker 可以并行任务实例的数量
parallelism=15

# 单个DAG最大并发数
# 默认是16，改成1，则在同⼀时间同⼀个DAG只有⼀个实例在跑
#等同于DAG实例中定义的max_active_runs参数
max_active_runs_per_dag = 16

#调度dag并发数
#等同于DAG实例中定义的concurrency参数
#如果DAG中未设置concurrency，scheduler将使用airflow.cfg的dag_concurrency作为默认值。
dag_concurrency=16

# 不加载example dag
# 这个配置只有在第一次启动airflow之前设置才有效
load_examples = False  

#检测新dag间隔
# 最好还是修改一下，因为默认为0，没有时间间隔， 很耗资源。
min_file_process_interval = 10

#Airflow UI 页面加载时间
#如果 dag 需要很长时间才能加载，可以减小default_dag_run_display_number的值。
#默认值为 25
default_dag_run_display_number= 15
sssssssssssss
#最大线程： scheduler 将并行生成多个线程来调度 dags
#默认值为2，可在生产中将此值增加到更大的值
max_threads = 2

#获取心跳和更新作业到数据库中的频率
#可增加到更高的值（例如 60 秒）
cheduler_heartbeat_sec = 60
```